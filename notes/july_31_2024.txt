Upgrading the way I handle identifiers to unlock operator overloading turned out to be a larger project than I thought. I'm almost there, though. I've changed so much that sometimes I don't know if the implementation in my head is what it currently is, or was. But I think I've narrowed my current issue down to block parsing.

Part of the problem is that I reordered Parser#make_expression at some point recently, and that matters. I rewrote part of it today, so now I don't remember what it was like at all. Another part of the problem is that I think there's still parsing ambiguity between a few syntaxes that I've wanted to use curlies.

	{ } 				# dictionary
	{ -> }				# anonymous block
	Class { }			# class declaration
	func { }			# func declaration
	func { params -> }	# func with params
	funk = { -> }		# assigning anonymous block
	map { }				# functional stuff
	funk() { }			# pass block to any function

This might be too confusing. Anyway, all of the following syntax was valid and evaluating as of last working state:

	{}				# {}
	{a b c}			# {"a" => nil, "b" => nil, "c" => nil}
	{a, b, c}		# {"a" => nil, "b" => nil, "c" => nil}
	{a, b c}		# {"a" => nil, "b" => nil, "c" => nil}
	{a: 1 b c = 2}	# {"a" =>   1, "b" => nil, "c" =>   2}

What if it should be like this:

	[] for arrays
	() for hashes and sets
	{} for block bodies at all times

I kind of like the idea of () being sets, more so than I like the idea of sets and hashes being basically the same thing. I think this would also open up the possibility of tuples again.

What about parsing tokens [func, ()]? How does the parser differentiate calls and empty sets?

	funk()
	[funk, ()]

	funk
	()
	[funk, ()]

	dunk.funk()
	[dunk.funk, ()]

I know that lexer gives newlines to the parser, so technically I should be able to differentiate between parens for a func call and parens for a set/hash.

	funk()
	[funk, ()]

	funk
	()
	[funk, \n, ()]

	dunk.funk()
	[dunk.funk, ()]

More on the hash and set syntax.

	(x, y)
	Set(x, y)

	(x, x)
	Set(x)

	(x=1, y=2) / (x:1, y:2)
	Hash(x=1, y=2)

	(x=123).x / (x=123)['x']
	123

I like this a lot. I can imagine it taking a while to get used to this syntax but it works really well. It looks nice, and it even reminds you of arguments for a function call. Aren't function args basically a set of values?

	funk { x, y = 12, z = 34 -> }
	[funk, (x, y=12, z=34)]

This frees up {} to be exclusive to blocks â€“ class block, function block, anon function block.

Some rules:
- each element in the set is an expression
- if an expr is an assignment_expr then extract ident and expression for key and value
- otherwise, expr goes into keys
	(x=1, y=2)
	(x:1, y:2)
	(x=123)

I think this should be valid

	(x=1, y)

Because under the hood, hashes use a set for the keys. So it makes sense to let you use it as both simultaneously.

	(x=1, y).x
	1

	(x=1, y).???
	there's no key for y

In this instance, the desired behavior is that the has only has one key in it, x. But it's set equivalent, has two things in it. They're basically the same class.

What about labeled arguments?

	funk(for: 123)

Labels should use : and hashes =. Or why not make them interchangeable?

	funk(for: 123)
	[Identifier_Expr(funk), Set(for : 123)]

	funk(for = 123)
	[Identifier_Expr(funk), Set(for = 123)]

	funk(123)
	[Identifier_Expr(funk), Set(123)]

	(for = 123)
	[Set(for = 123)]

	funk
	(for = 123)
	[Identifier_Expr(funk), \n, Set(for = 123)]

Fuck, what about parenthesized expressions? (1 + 2). I solved that, I think. See Parser#make_expression curr? '('

Anyway, I've come to the conclusion that my woes won't go away until I fix the lexer. I completely broke it, and it's now producing incorrect tokens. The problem currently is that I don't have solid rules for what can and cannot be an identifier. I tried to hack on a way to make identifiers out of multiple symbols but that then broken block parsing. I need to step back and think about identifiers.

RESERVED WORDS, identifiers that cannot be overloaded:

	while ew el elswhile elwhile else
	if ef el elsif elif else
	return skip stop
	unless until
	and or
	operator
	self new nil
	where map tap
	yes no true false
	pri private pub public

SYMBOLS, some will be reserved, some won't

	= : ; , . .? ( { [ ] } )
	+ - ~ * ! @ # $ % ^ & ? / | \ _
	?? && || << >> ** .. .< >. >< <>
	!== === >== == != <= >= < >
	+= -= *= |= /= %= &= ^= .= =; <<= >>=
	>!!! >!! >! >~
	.../ ../ ./
	:: ->
	` 		comments
	``` 	multiline comments

You could theoretically redeclare any of these symbols above and alter the behavior, but the question is, which ones can and cannot be overloaded?

Of the RESERVED SYMBOLS, these CANNOT be overloaded:

	( { [ ] } ) = =; : ; ,				Crucial for program structure, assignment, sets, arg labels
	+= -= *= |= /= %= &= ^= .= <<= >>=	Assignment shorthand
	>!!! >!! >! >~						Console output and debugger
	.../ ../ ./							Namespace identifier
	.. .< >. ><							Range syntax
	:: ->								Function syntax
	` ```								Never make it to Parser so ignored

The remainder CAN be overloaded (with the exception of backslash, I'm not sold on allowing that.)

	. + - ~ * ! @ # $ % ^ & ? / | \ _
	?? && || << >> ** <>
	!== === >== == != <= >= < >

Using pry, I broke these down into their characters. It removed the backslash because I didn't escape it so let's save ourselves the headache and ban it from being used as an identifier. That leaves us with these VALID SYMBOLS:

	. + - ~ * ! @ # $ % ^ & ? / | < > = _

So use any combination of a-z, 0-9, and these symbols to create an identifier. But only following these rules:

	1) ident is not equal to a reserved word or reserved symbol
	2) ident can start with: 	a-z, any valid symbol
	3) ident can end with:		a-z, 0-9, any valid symbol
	4) middle:					a-z, 0-9, any valid symbol

Some examples off the top of my head, that appear to be valid:

	1 +/- 2			infix +/-
	$ 100 or $100	prefix $
	42 % or 42%		postfix %

Hm, I do worry about +/-, what if there's no space? +/-2 would become one identifier. But maybe that's okay? It's the programmer's mistake. They should have the power to do this, but if it's bad practice, don't do it. So anyway, this +/- 2 could parse in different ways just based on the spacing

	+/-2		identifier(+/-2)
	+ /-2		prefix(+) identifier(/-2)
	+/ -2		prefix(+/)	number(-2)

If your identifiers are properly separated, then it doesn't matter if the pre or postfix operator has a space. In this example from the most recent working state, the lexer correctly identified $ as its own symbol and 100 as a number:

	$100
	undeclared '$' in String { types, Info, info, call_me }
	$ 100
	undeclared '$' in String { types, Info, info, call_me }

	(Ignore that it says undeclared, the important point is that it recognized $ as a separate identifier in both cases.)

The last question is, what type of tokens do they become?

	Reserved words definitely Keyword_Token
	Reserved symbols definitely Keyword_Token
	The remainder, Identifier_Token

Anyway, I guess I need to refactor Lexer to accommodate these new rules, now that I'm clear on how to move forward.

	1) Make #lex tokenize reserved words and symbols
	2) Make identifiers based on new rules, including the multi-symbol ones

I think I'll take this opportunity to really clean up Lexer. It's the first class I wrote, before I knew how any of this worked. Once these two steps are done and working correctly. Then we can think about how to update the Parser to work with these new tokens.
